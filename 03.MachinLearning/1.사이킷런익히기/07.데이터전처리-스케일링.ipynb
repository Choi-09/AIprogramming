{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5fccb9",
   "metadata": {},
   "source": [
    "# 7. 데이터 전처리-스케일링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d89603",
   "metadata": {},
   "source": [
    "## 2) 데이터 스케일링 (피처 스케일링)\n",
    "1) 표준화: 데이터의 피처 각각을 평균0, 분산1인 가우시안 정규분포를 가진 값으로 변환\n",
    "> StandardScaler: 평균0, 분산1인 정규 분포 형태로 변환\n",
    "\n",
    "2) 정규화: 서로 다른 피처의 크기를 통일하기 위해 크기 변환\n",
    "> MinMaxScaler: 데이터 값을 0과 1사이의 값으로 변환 (음수가 있으면 -1~1 사이)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3987e525",
   "metadata": {},
   "source": [
    "### (2-1) 피처 스케일링과 표준화\n",
    "+ StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52d6858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균 값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data = iris_data, columns = iris.feature_names)\n",
    "\n",
    "print('feature 들의 평균 값')\n",
    "print(iris_df.mean())\n",
    "print('\\nfeature 들의 분산 값')\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729caf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균 값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. 모듈 임포트\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 2. StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 3. fit() 으로 mean, var 구하기 \n",
    "scaler.fit(iris_df) # dataframe, ndarray 모두 들어올수있다.\n",
    "\n",
    "# 4. transform으로 데이터셋 변환. \n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# 5. transform()하면 scale변환된 데이터 셋이 numpy array로 반환되어 이것을 DF로 변환\n",
    "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns = iris.feature_names)\n",
    "print('feature 들의 평균 값')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\nfeature 들의 분산 값')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce834e",
   "metadata": {},
   "source": [
    "### (2-2) 피처 스케일링과 정규화\n",
    "+ MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ff6b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 최소 값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 최대 값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. 모듈임포트\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 2. MinMaxScaler 객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 3. fit()으로 max와 mean 구하기 \n",
    "scaler.fit(iris_df)\n",
    "\n",
    "# 4. transform()으로 데이터셋 변환 \n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# 5. transform()하면 scale 변환된 데이터 셋이 numpy ndarray로 반환되어 이를 DF로 변환\n",
    "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns = iris.feature_names)\n",
    "\n",
    "print('feature 들의 최소 값')\n",
    "print(iris_df_scaled.min())\n",
    "print('\\nfeature 들의 최대 값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa9c36",
   "metadata": {},
   "source": [
    "##### 2-3) Scaler를 이용하여 학습 데이터와 테스트 데이터에 fit(), transform(), fit_transform() 적용 시 유의사항. \n",
    "+ train, test 데이터 세트에 각각 표준화, 정규화하면 이슈 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9369e39",
   "metadata": {},
   "source": [
    "##### > train dataset, test dataset에 각각 fit(), transform() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c397d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_array1 형태:  (11,)\n",
      "train_array2 형태:  (11, 1)\n",
      "test_array1 형태:  (6,)\n",
      "test_array2 형태:  (6, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 학습 데이터는 0부터 10까지, 테스트 데이터는 0부터 5까지 값을 가지는 데이터 세트로 생성한다. \n",
    "# Scaler클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1,1)로 차원 변경\n",
    "train_array = np.arange(0,11).reshape(-1,1)\n",
    "test_array = np.arange(0,6).reshape(-1,1)\n",
    "\n",
    "train_array1 = np.arange(0,11)\n",
    "train_array2 = np.arange(0,11).reshape(-1,1)\n",
    "test_array1 = np.arange(0,6)\n",
    "test_array2 = np.arange(0,6).reshape(-1,1)\n",
    "\n",
    "print('train_array1 형태: ', train_array1.shape)\n",
    "print('train_array2 형태: ', train_array2.shape)\n",
    "print('test_array1 형태: ', test_array1.shape)\n",
    "print('test_array2 형태: ', test_array2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48462567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "# 최소값 0, 최대값 1로 변환하는 MinMaxScaler객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit()하게 되면 train_array 데이터의 최소값이 0, 최대값이 10으로 설정.  \n",
    "scaler.fit(train_array)\n",
    "\n",
    "# 1/10 scale로 train_array 데이터 변환함. 원본 10-> 1로 변환됨.\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
    "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b343bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "Scale된 test_array 데이터: [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# 앞에서 생성한 MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최소값이 0, 최대값이 5으로 설정됨 \n",
    "scaler.fit(test_array)\n",
    "\n",
    "# 1/5 scale로 test_array 데이터 변환함. 원본 5->1로 변환.  \n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "print('원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
    "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e36c302",
   "metadata": {},
   "source": [
    "##### => train에서는 5가 0.5 로 변환되었는데 test에서는 5가 1.0으로 변환되면서 척도가 달라졌기 때문에 문제 발생! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8adfd6e",
   "metadata": {},
   "source": [
    "##### > 올바른 Scaling\n",
    "+ train과 test 모두 동일한 기준에서 scaling 되어야하기 때문에 <br/>\n",
    "  test 데이터에서는 fit() 하지 않고 transform()만 해준다. train의 fit을 따른다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b68c1a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "\n",
      "원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "Scale된 test_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
    "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n",
    "\n",
    "# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform() 만으로 변환해야 함. \n",
    "test_scaled = scaler.transform(test_array)\n",
    "print('\\n원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
    "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
